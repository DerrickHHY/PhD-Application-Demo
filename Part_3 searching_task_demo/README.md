# Visual Searching Paradigm for QCE

To achieve the Visual Memory Queci-Comprehensive Exploration (QCE or CE) study, proposed by Prof. Huang Liqiang, my research plan employs an online video-game visual searching paradigm to construct a large-scale dataset. Part 3 is set to show the current video demonstration and project files.

The following video demonstrates a single trial of this searching paradigm. Each trial commences upon the participant's readiness and active clicking. Begin with the presentation of a fixation, followed by a searching cue indicating the target object to be found in the trial, exemplified here by the search for a printer. After another fixation, the searching task is initiated. Participant is positioned in a corner of the virtual room, and is permitted to adjust their viewpoint and location for searching the target object. Via mouse or touchscreen, participants can click on all visible objects, while a lower-left textbox displays the object's name. If I find and click the target object within 45 seconds, the trial terminates and informs success; otherwise, it informs failure. 

Video demonstration:

[https://github.com/user-attachments/assets/eb29b1bf-8d09-470f-b6d3-a8bf9cafb79a](https://github.com/user-attachments/assets/eb29b1bf-8d09-470f-b6d3-a8bf9cafb79a)

Note: Not all code was produced entirely by myself! LLM Deepseek provided significant assistance, including recommendations for suitable packages, necessary double-checking, debugging support, and interpretation of fundamental code.

